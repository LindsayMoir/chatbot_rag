{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Chatbot Using Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "I want an assistant that can tell me if the scientific information that I am receiving is current. ChatGPT3.5 is only trained to January 2022. So, anything past that, it will not have the information or ... it will lie:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1e0e9",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05152566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "from openai import OpenAI # for calling the OpenAI API\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "import requests\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "We will use Wikipedia as our source. Put the RAG text into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e749c7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024 in science']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I was originally going to do multiple topics, but decided to just do one\n",
    "topics = ['2024 in science']\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(topic):\n",
    "    # Base URL of the Wikimedia API\n",
    "    base_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"titles\": topic\n",
    "    }\n",
    "    \n",
    "    # Send a GET request to the Wikimedia API\n",
    "    response = requests.get(base_url, params=params)\\\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96bf928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchcomplete': '',\n",
      " 'query': {'pages': {...}},\n",
      " 'warnings': {'extracts': {...}}}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "topic = topics[0]\n",
    "data = get_wikipedia_content(topic)\n",
    "\n",
    "# Create a PrettyPrinter object with desired configurations\n",
    "pp = pprint.PrettyPrinter(width=40, depth=2)\n",
    "\n",
    "# Print the data\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60d76354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'74041015'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the key from the nested JSON object. We just want the first hit.\n",
    "# We will need this later.\n",
    "pages = data['query']['pages']\n",
    "page_key = list(pages.keys())[0]\n",
    "page_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8d5654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events(html):\n",
    "    events = {}\n",
    "    current_date = None\n",
    "\n",
    "    # Find all occurrences of dates in the format \"digit space Month\"\n",
    "    date_pattern = r'\\b(\\d{1,2}\\s(?:January|February|March|April|May|June|July|August|September|October|November|December))\\b'\n",
    "    dates = re.findall(date_pattern, html)\n",
    "    \n",
    "    # Define the pattern to match HTML tags\n",
    "    html_tags_pattern = re.compile(r'<.*?>')\n",
    "\n",
    "    for date in dates:\n",
    "        if current_date is not None:\n",
    "            current_event = []\n",
    "\n",
    "        current_date = date\n",
    "\n",
    "        # Find the text between two consecutive dates\n",
    "        event_pattern = re.escape(date) + r'(.*?)' + re.escape(dates[dates.index(date) + 1] if dates.index(date) < len(dates) - 1 else '')\n",
    "        event_text_match = re.search(event_pattern, html, re.DOTALL)\n",
    "        \n",
    "        # Where there are multiple events on a date split those into a list.\n",
    "        if event_text_match:\n",
    "            event_text = event_text_match.group(1)\n",
    "            if event_text.startswith('\\n<ul><li>'):\n",
    "                event_text_list = event_text.split('</li>')\n",
    "                cleaned_value = [remove_html_and_newlines(item) for item in event_text_list]\n",
    "                cleaned_value = [value for value in cleaned_value if value != '']  \n",
    "                event_text = cleaned_value\n",
    "            else:\n",
    "                event_text = [remove_html_and_newlines(event_text)]\n",
    "\n",
    "            events[current_date] = event_text\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "490536ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_newlines(text):\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    cleaned_text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove newline characters\n",
    "    cleaned_text = cleaned_text.replace('\\n', '')\n",
    "    \n",
    "    # Remove any extra whitespace\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7940ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into events_dict\n",
    "data = get_wikipedia_content(topics[0])\n",
    "\n",
    "# We just want the extract\n",
    "extract = data['query']['pages'][page_key]['extract']\n",
    "\n",
    "# Create the dictionary\n",
    "events_dict = extract_events(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "588d89d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['– The first functional semiconductor made from graphene is created.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and see what they look like.\n",
    "events_dict['3 January']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c976ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Scientists report studies which seem to support the hypothesis that life may have begun in a shallow lake rather than otherwise - perhaps somewhat like a \"warm little pond\" originally proposed by Charles Darwin.',\n",
       " 'A group of scientists from around the globe have charted paradigm shifting restorative pathways to mitigate the worst effects of climate change and biodiversity loss with a strong emphasis on environmental sustainability, human wellbeing and reducing social and economic inequality.',\n",
       " 'Researchers have discovered a new phase of matter, named a \"light-matter hybrid\", which may reshape understanding of how light interacts with matter.',\n",
       " \"A study of proteins in cerebrospinal fluid indicates there are five subtypes of Alzheimer's disease, suggesting it to be likely that subtype-specific treatments are required.\",\n",
       " 'A study finds seaweed farming could be set up as a resilient food solution within roughly a year in abrupt sunlight reduction scenarios such as after a nuclear war or a large volcano eruption.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what happens when there is more than one event on a date\n",
    "print(len(events_dict['9 January']))\n",
    "events_dict['9 January']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f7c1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all values from events_dict with keys prepended\n",
    "all_values = [f\"{key} {value}\" for key, values_list in events_dict.items() for value in values_list]\n",
    "length = len(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "651a48d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 January – The Japan Meteorological Agency (J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 January – The first functional semiconductor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 January – A review indicates digital rectal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 January Scientists report that newborn galax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 January An analysis of sugar-sweetened bever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8 May Atmospheric gases surrounding 55 Cancri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>9 May – A record annual increase in atmospheri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10 May – A series of solar storms and intense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>13 May – OpenAI reveals GPT-4o, its latest AI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>15 May</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    2 January – The Japan Meteorological Agency (J...\n",
       "1    3 January – The first functional semiconductor...\n",
       "2    4 January – A review indicates digital rectal ...\n",
       "3    5 January Scientists report that newborn galax...\n",
       "4    5 January An analysis of sugar-sweetened bever...\n",
       "..                                                 ...\n",
       "99   8 May Atmospheric gases surrounding 55 Cancri ...\n",
       "100  9 May – A record annual increase in atmospheri...\n",
       "101  10 May – A series of solar storms and intense ...\n",
       "102  13 May – OpenAI reveals GPT-4o, its latest AI ...\n",
       "103                                            15 May \n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe to hold the text\n",
    "df = pd.DataFrame(data={'text': all_values}, index=range(length))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "Get the embeddings for the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "582f0656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x2007b552b50>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get OpenAI key\n",
    "open_ai_key = pd.read_csv('D:\\OneDrive\\Security\\keys.csv')\n",
    "open.ai_key = open_ai_key[open_ai_key['Organization'] == 'Open_AI']['Key'][0]\n",
    "\n",
    "client = OpenAI(api_key = open.ai_key)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text_to_embed):\n",
    "    \"\"\"Get the embeddings for the text\"\"\"\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text_to_embed\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "# Call the embeddings function\n",
    "response = get_embedding(df['text'].tolist())\n",
    "print(len(response.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "74280b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 January – The Japan Meteorological Agency (J...</td>\n",
       "      <td>Embedding(embedding=[-0.0031084921211004257, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 January – The first functional semiconductor...</td>\n",
       "      <td>Embedding(embedding=[0.002213209867477417, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 January – A review indicates digital rectal ...</td>\n",
       "      <td>Embedding(embedding=[-0.023844994604587555, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 January Scientists report that newborn galax...</td>\n",
       "      <td>Embedding(embedding=[0.0041982680559158325, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 January An analysis of sugar-sweetened bever...</td>\n",
       "      <td>Embedding(embedding=[0.004905147943645716, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8 May Atmospheric gases surrounding 55 Cancri ...</td>\n",
       "      <td>Embedding(embedding=[0.010995185934007168, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>9 May – A record annual increase in atmospheri...</td>\n",
       "      <td>Embedding(embedding=[-0.006700010970234871, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10 May – A series of solar storms and intense ...</td>\n",
       "      <td>Embedding(embedding=[-0.011253030970692635, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>13 May – OpenAI reveals GPT-4o, its latest AI ...</td>\n",
       "      <td>Embedding(embedding=[-0.022428754717111588, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>15 May</td>\n",
       "      <td>Embedding(embedding=[-0.024619681760668755, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    2 January – The Japan Meteorological Agency (J...   \n",
       "1    3 January – The first functional semiconductor...   \n",
       "2    4 January – A review indicates digital rectal ...   \n",
       "3    5 January Scientists report that newborn galax...   \n",
       "4    5 January An analysis of sugar-sweetened bever...   \n",
       "..                                                 ...   \n",
       "99   8 May Atmospheric gases surrounding 55 Cancri ...   \n",
       "100  9 May – A record annual increase in atmospheri...   \n",
       "101  10 May – A series of solar storms and intense ...   \n",
       "102  13 May – OpenAI reveals GPT-4o, its latest AI ...   \n",
       "103                                            15 May    \n",
       "\n",
       "                                            embeddings  \n",
       "0    Embedding(embedding=[-0.0031084921211004257, -...  \n",
       "1    Embedding(embedding=[0.002213209867477417, 0.0...  \n",
       "2    Embedding(embedding=[-0.023844994604587555, 0....  \n",
       "3    Embedding(embedding=[0.0041982680559158325, 0....  \n",
       "4    Embedding(embedding=[0.004905147943645716, -0....  \n",
       "..                                                 ...  \n",
       "99   Embedding(embedding=[0.010995185934007168, 0.0...  \n",
       "100  Embedding(embedding=[-0.006700010970234871, -0...  \n",
       "101  Embedding(embedding=[-0.011253030970692635, -0...  \n",
       "102  Embedding(embedding=[-0.022428754717111588, -0...  \n",
       "103  Embedding(embedding=[-0.024619681760668755, 0....  \n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the embeddings to the dataframe\n",
    "df['embeddings'] = response.data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "41a761aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and make sure they are ok. You expect a length of 1536\n",
    "temp = df['embeddings'].iloc[0]\n",
    "len(temp.dict()['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aca6dc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_check_frozen', '_copy_and_set_values', '_get_value', '_iter', 'construct', 'copy', 'dict', 'embedding', 'from_orm', 'index', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'object', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'to_dict', 'to_json', 'update_forward_refs', 'validate']\n"
     ]
    }
   ],
   "source": [
    "# Did a dir on the object. There is a dict method. Use that to get the embeddings.\n",
    "print(dir(df['embeddings'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d658b076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_floats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 January – The Japan Meteorological Agency (J...</td>\n",
       "      <td>Embedding(embedding=[-0.0031084921211004257, -...</td>\n",
       "      <td>[-0.0031084921211004257, -0.0093239089474082, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 January – The first functional semiconductor...</td>\n",
       "      <td>Embedding(embedding=[0.002213209867477417, 0.0...</td>\n",
       "      <td>[0.002213209867477417, 0.012299963273108006, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 January – A review indicates digital rectal ...</td>\n",
       "      <td>Embedding(embedding=[-0.023844994604587555, 0....</td>\n",
       "      <td>[-0.023844994604587555, 0.014986811205744743, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 January Scientists report that newborn galax...</td>\n",
       "      <td>Embedding(embedding=[0.0041982680559158325, 0....</td>\n",
       "      <td>[0.0041982680559158325, 0.002656512660905719, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 January An analysis of sugar-sweetened bever...</td>\n",
       "      <td>Embedding(embedding=[0.004905147943645716, -0....</td>\n",
       "      <td>[0.004905147943645716, -0.0037844462785869837,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8 May Atmospheric gases surrounding 55 Cancri ...</td>\n",
       "      <td>Embedding(embedding=[0.010995185934007168, 0.0...</td>\n",
       "      <td>[0.010995185934007168, 0.005310845095664263, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>9 May – A record annual increase in atmospheri...</td>\n",
       "      <td>Embedding(embedding=[-0.006700010970234871, -0...</td>\n",
       "      <td>[-0.006700010970234871, -0.002503804862499237,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10 May – A series of solar storms and intense ...</td>\n",
       "      <td>Embedding(embedding=[-0.011253030970692635, -0...</td>\n",
       "      <td>[-0.011253030970692635, -0.009003724902868271,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>13 May – OpenAI reveals GPT-4o, its latest AI ...</td>\n",
       "      <td>Embedding(embedding=[-0.022428754717111588, -0...</td>\n",
       "      <td>[-0.022428754717111588, -0.01023862510919571, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>15 May</td>\n",
       "      <td>Embedding(embedding=[-0.024619681760668755, 0....</td>\n",
       "      <td>[-0.024619681760668755, 0.005405304487794638, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    2 January – The Japan Meteorological Agency (J...   \n",
       "1    3 January – The first functional semiconductor...   \n",
       "2    4 January – A review indicates digital rectal ...   \n",
       "3    5 January Scientists report that newborn galax...   \n",
       "4    5 January An analysis of sugar-sweetened bever...   \n",
       "..                                                 ...   \n",
       "99   8 May Atmospheric gases surrounding 55 Cancri ...   \n",
       "100  9 May – A record annual increase in atmospheri...   \n",
       "101  10 May – A series of solar storms and intense ...   \n",
       "102  13 May – OpenAI reveals GPT-4o, its latest AI ...   \n",
       "103                                            15 May    \n",
       "\n",
       "                                            embeddings  \\\n",
       "0    Embedding(embedding=[-0.0031084921211004257, -...   \n",
       "1    Embedding(embedding=[0.002213209867477417, 0.0...   \n",
       "2    Embedding(embedding=[-0.023844994604587555, 0....   \n",
       "3    Embedding(embedding=[0.0041982680559158325, 0....   \n",
       "4    Embedding(embedding=[0.004905147943645716, -0....   \n",
       "..                                                 ...   \n",
       "99   Embedding(embedding=[0.010995185934007168, 0.0...   \n",
       "100  Embedding(embedding=[-0.006700010970234871, -0...   \n",
       "101  Embedding(embedding=[-0.011253030970692635, -0...   \n",
       "102  Embedding(embedding=[-0.022428754717111588, -0...   \n",
       "103  Embedding(embedding=[-0.024619681760668755, 0....   \n",
       "\n",
       "                                     embeddings_floats  \n",
       "0    [-0.0031084921211004257, -0.0093239089474082, ...  \n",
       "1    [0.002213209867477417, 0.012299963273108006, -...  \n",
       "2    [-0.023844994604587555, 0.014986811205744743, ...  \n",
       "3    [0.0041982680559158325, 0.002656512660905719, ...  \n",
       "4    [0.004905147943645716, -0.0037844462785869837,...  \n",
       "..                                                 ...  \n",
       "99   [0.010995185934007168, 0.005310845095664263, -...  \n",
       "100  [-0.006700010970234871, -0.002503804862499237,...  \n",
       "101  [-0.011253030970692635, -0.009003724902868271,...  \n",
       "102  [-0.022428754717111588, -0.01023862510919571, ...  \n",
       "103  [-0.024619681760668755, 0.005405304487794638, ...  \n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embeddings from the object using the dict method\n",
    "df['embeddings_floats'] = df['embeddings'].apply(lambda x: x.dict()['embedding'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43f351f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and make sure that worked. Should get 1536\n",
    "len(df['embeddings_floats'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8b0d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample question\n",
    "question = 'Where did life probably begin?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ebfedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(question, df):\n",
    "    \n",
    "    # Get embedding for question from openai\n",
    "    \n",
    "    question_embeddings = client.embeddings.create(\n",
    "        input = question, \n",
    "        model = \"text-embedding-ada-002\").data[0].embedding\n",
    "    \n",
    "    return question_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "127c001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cosign_similarity(question_embeddings, df):\n",
    "\n",
    "    # Calculate the cosign similarity between the question and the embeddings\n",
    "\n",
    "    # Convert 'embeddings_floats' column to numpy array\n",
    "    embeddings_array = np.array(df['embeddings_floats'].tolist())\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_sims = [cosine(question_embeddings, embedding) for embedding in embeddings_array]\n",
    "\n",
    "    # Assign the cosine similarity to a new column in the DataFrame\n",
    "    df['cosine_sims'] = cosine_sims\n",
    "\n",
    "    # Sort the DataFrame by 'cosine_sims' column in ascending order\n",
    "    df.sort_values('cosine_sims', inplace=True)\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return df['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1ca14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 January Scientists report studies which seem to support the hypothesis that life may have begun in a shallow lake rather than otherwise - perhaps somewhat like a \"warm little pond\" originally proposed by Charles Darwin.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question_embeddings = get_embeddings(question, df)\n",
    "answer = calc_cosign_similarity(question_embeddings, df)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c99ef22",
   "metadata": {},
   "source": [
    "## Performance \n",
    "The purpose of this is to show the efficacy of RAG. I am going to pull out items from the pandas dataframe. Submit those to ChatGPT and have it return a question. Then I am going to use that question to see what the results are for the 3 different versions. \n",
    "\n",
    "- ChatGPT unassisted\n",
    "- Vector look up\n",
    "- ChatGPT assisted with RAG\n",
    "\n",
    "I could use input() and type the questions in but ... I hate typing and this is a far more interesting use of the technology. I could also, change the model that is generating the questions but ... that is for another day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1ba6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_answer(question):\n",
    "\n",
    "    # https://platform.openai.com/docs/guides/text-generation/chat-completions-api\n",
    "\n",
    "    # send a ChatCompletion request\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [\n",
    "            {'role': 'user', \n",
    "             'content': question}\n",
    "        ],\n",
    "        temperature = 0\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6595e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer_comparison(question, df):   \n",
    "    \n",
    "    # Using vector look up\n",
    "    question_embeddings = get_embeddings(question, df)\n",
    "    answer = calc_cosign_similarity(question_embeddings, df)\n",
    "    print('\\n', 'Using cosine similarity\\n', answer)\n",
    "    \n",
    "    # GPT3 vanilla\n",
    "    response = chatgpt_answer(question)\n",
    "    print('\\nChatGPT3.5 Unassisted\\n', response.choices[0].message.content)\n",
    "    \n",
    "    # Using rag\n",
    "    question_embeddings = get_embeddings(question, df)\n",
    "    response = chatgpt_answer(rag_prompt(question, df))\n",
    "    print('\\nChatGPT3.5 with RAG\\n', response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff4eec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_prompt(question, df):\n",
    "    \"\"\"Ceate a prompt that has the content from the pandas df\"\"\"\n",
    "    \n",
    "    # Get the embeddings\n",
    "    question_embeddings = get_embeddings(question, df)\n",
    "    \n",
    "    # Get the text\n",
    "    text = calc_cosign_similarity(question_embeddings, df)\n",
    "    \n",
    "    # Create the prompt\n",
    "    message = f\"You are an experienced scientific researcher. {question} Please consider this \\\n",
    "information when formulating your response. Pay particular attention to the date. \\\n",
    "I am looking for the most recent information. The dates in this text are all 2024. {text}. \\\n",
    "Restrict your answer to ONLY what is in this text.\"\n",
    "    \n",
    "    # Get rid of extra spaces\n",
    "    message = message.strip(' ')\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4742e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_prompt(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    input df - pandas dataframe\n",
    "    \n",
    "    Does the following:\n",
    "    Takes in the df. \n",
    "    Randomly selects a text item. \n",
    "    Creates a prompt from the text\n",
    "    Submits it to ChatGPT and asks it to summarize and turn it into a question.\n",
    "    \n",
    "    output question - str\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a random piece of txt\n",
    "    text = df.sample(1)['text'].iloc[0]\n",
    "    \n",
    "    # Create prompt\n",
    "    message = f\"You are an experienced scientific researcher. Formulate a Question based on this {text}. \\\n",
    "In the Question use at least some of these words 'who, when, where, how much, what quantity'.\"\n",
    "    \n",
    "    # Submit to ChatGPT\n",
    "    response = chatgpt_answer(message)\n",
    "    \n",
    "    # Just the response\n",
    "    question = response.choices[0].message.content\n",
    "    \n",
    "    # Just get the question\n",
    "    question = question.split('\\n\\n')[-1]\n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2c1c4",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ccd8062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What quantity of funding has been allocated for the development and launch of the Laser Interferometer Space Antenna (LISA) by the European Space Agency (ESA), and when and where is it scheduled to launch in 2035?',\n",
       " \"How much funding was allocated to Japan's SLIM mission, which successfully achieved a soft landing on the Moon on 19 January, making Japan the fifth country to accomplish this feat?\",\n",
       " 'How much cosmic dust particles have potentially spread life to Earth and elsewhere in the Universe through the process of panspermia?',\n",
       " 'How much high-resolution information on neural activity can be captured at depths of 250 micrometers in mouse brains using a graphene-based implant in combination with a two-photon microscope?',\n",
       " 'How much coral bleaching has occurred globally during the fourth event confirmed by NOAA on 15 April, and where is it predominantly taking place?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets ask some questions\n",
    "questions_list = [summarize_prompt(df) for _ in range(5)]\n",
    "questions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a44b6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      " What quantity of funding has been allocated for the development and launch of the Laser Interferometer Space Antenna (LISA) by the European Space Agency (ESA), and when and where is it scheduled to launch in 2035?\n",
      "\n",
      " Using cosine similarity\n",
      " 25 January – The Laser Interferometer Space Antenna (LISA) is given the go-ahead by the European Space Agency (ESA). It will launch in 2035.\n",
      "\n",
      "ChatGPT3.5 Unassisted\n",
      " The European Space Agency (ESA) has allocated a budget of €1.1 billion for the development and launch of the Laser Interferometer Space Antenna (LISA). The mission is scheduled to launch in 2035 from the Guiana Space Centre in Kourou, French Guiana.\n",
      "\n",
      "ChatGPT3.5 with RAG\n",
      " The European Space Agency (ESA) has allocated funding for the development and launch of the Laser Interferometer Space Antenna (LISA). The project was given the go-ahead on 25 January 2024, and it is scheduled to launch in 2035.\n",
      "None \n",
      "#########\n",
      "\n",
      "2 \n",
      " How much funding was allocated to Japan's SLIM mission, which successfully achieved a soft landing on the Moon on 19 January, making Japan the fifth country to accomplish this feat?\n",
      "\n",
      " Using cosine similarity\n",
      " 19 January – Japan becomes the fifth country to achieve a soft landing on the Moon, with its SLIM mission.\n",
      "\n",
      "ChatGPT3.5 Unassisted\n",
      " The SLIM mission, which stands for Smart Lander for Investigating Moon, received a funding of approximately 18.5 billion yen (around $170 million) from the Japanese government.\n",
      "\n",
      "ChatGPT3.5 with RAG\n",
      " Based on the information provided in the text, it does not specify the exact amount of funding allocated to Japan's SLIM mission.\n",
      "None \n",
      "#########\n",
      "\n",
      "3 \n",
      " How much cosmic dust particles have potentially spread life to Earth and elsewhere in the Universe through the process of panspermia?\n",
      "\n",
      " Using cosine similarity\n",
      " 7 February Reported science studies suggest that cosmic dust particles may have spread, in a process termed panspermia, life to Earth and elsewhere in the Universe.\n",
      "\n",
      "ChatGPT3.5 Unassisted\n",
      " It is difficult to quantify exactly how much cosmic dust particles have potentially spread life to Earth and elsewhere in the Universe through panspermia. Panspermia is a hypothesis that suggests life could have been transferred between planets and even between star systems by objects like meteoroids, asteroids, and comets carrying microbial life forms.\n",
      "\n",
      "While there is evidence to suggest that cosmic dust particles could potentially carry microbial life forms, the exact extent of their role in spreading life throughout the Universe is still a topic of ongoing research and debate. It is possible that cosmic dust particles have played a significant role in the spread of life, but the exact amount and impact of this process are not yet fully understood.\n",
      "\n",
      "ChatGPT3.5 with RAG\n",
      " The reported science studies suggest that cosmic dust particles may have spread life to Earth and elsewhere in the Universe through the process of panspermia.\n",
      "None \n",
      "#########\n",
      "\n",
      "4 \n",
      " How much high-resolution information on neural activity can be captured at depths of 250 micrometers in mouse brains using a graphene-based implant in combination with a two-photon microscope?\n",
      "\n",
      " Using cosine similarity\n",
      " 11 January A graphene-based implant on the surface of mouse brains, in combination with a two-photon microscope, is shown to capture high-resolution information on neural activity at depths of 250 micrometers.\n",
      "\n",
      "ChatGPT3.5 Unassisted\n",
      " A graphene-based implant in combination with a two-photon microscope can capture high-resolution neural activity information at depths of up to 250 micrometers in mouse brains. This technology allows for precise monitoring of neural activity in deep brain regions with high spatial and temporal resolution.\n",
      "\n",
      "ChatGPT3.5 with RAG\n",
      " Based on the information provided in the text from January 11, 2024, a graphene-based implant on the surface of mouse brains, in combination with a two-photon microscope, is capable of capturing high-resolution information on neural activity at depths of 250 micrometers.\n",
      "None \n",
      "#########\n",
      "\n",
      "5 \n",
      " How much coral bleaching has occurred globally during the fourth event confirmed by NOAA on 15 April, and where is it predominantly taking place?\n",
      "\n",
      " Using cosine similarity\n",
      " 15 April – The NOAA confirms a fourth global coral bleaching event.\n",
      "\n",
      "ChatGPT3.5 Unassisted\n",
      " During the fourth global coral bleaching event confirmed by NOAA on 15 April, approximately 75% of the world's coral reefs have experienced bleaching to some extent. This event has predominantly taken place in the Pacific Ocean, particularly in regions such as the Great Barrier Reef in Australia, the Hawaiian Islands, and the Pacific Islands. Other affected areas include the Indian Ocean, the Caribbean, and parts of the Atlantic Ocean.\n",
      "\n",
      "ChatGPT3.5 with RAG\n",
      " As of 15 April 2024, the NOAA has confirmed a fourth global coral bleaching event. The extent of coral bleaching occurring globally during this event has not been specified in the provided information. Additionally, the specific locations where the bleaching is predominantly taking place have not been mentioned.\n",
      "None \n",
      "#########\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, question in enumerate(questions_list):\n",
    "    print(idx + 1, '\\n', question)\n",
    "    print(question_answer_comparison(question, df), '\\n#########\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d43421",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "ChatGPT unassisted is amazingly good at lying. When it does not know the answer, it simply dreams something up. Since, ChatGPT is  so good at lying and it is trained on a large corpus, some of its \"lies\" may actually be truths. Just because it happened sometime on or before January 2022 does not mean it is not true today. It still could be true and part of a valid response. \n",
    "\n",
    "When I asked ChatGPT with RAG to restrict its answers to the input text it did not lie anymore and ws very accurate. I ran this code several times and on average ChatGPT 3.5 Unassisted got ~ 30% wrong. That is almost certainly a problem for most Chatbot applications. ChatGPT 3.5 With RAG was always correct but ... could not answer the question completely sometimes because the question posed by ChatGPT 3.5 Unassisted wanted information that was not in the RAG prompt. This was not common but did happen. \n",
    "\n",
    "When giving the LLM context, I did not return more than one result with this implementation. It is common to return the top several results to give the Large Language Model (LLM) more to work with. Since the sample size was so small and the individual pieces of information on the page were not expected to be closesly related, this is fine. However, depending on the application this may not be and would probably require some more prompt engineering to make sure that the application performed consistently well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79200ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "333.474px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
